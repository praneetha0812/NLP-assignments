{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9eedb2f9",
   "metadata": {},
   "source": [
    "# Home work2- Question no2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "17d3886d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\13179\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('brown')\n",
    "\n",
    "from nltk.corpus import brown\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "88882f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data = brown.sents(categories='news')\n",
    "romance_data = brown.sents(categories='romance')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdf25d7",
   "metadata": {},
   "source": [
    "#  Function to preprocess sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2e3c6bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_sentences(sentences):\n",
    "    preprocessed = []\n",
    "    for sentence in sentences:\n",
    "        # Lowercase all words and remove tokens that consist only of punctuation\n",
    "        tokens = ['<s>']\n",
    "        for word in sentence:\n",
    "            word = word.lower()\n",
    "            if word not in string.punctuation and any(c.isalnum() for c in word):\n",
    "                tokens.append(word)\n",
    "        tokens.append('</s>')\n",
    "        preprocessed.append(tokens)\n",
    "    return preprocessed\n",
    "\n",
    "# Function to compute unigram and bigram models\n",
    "def compute_models(sentences):\n",
    "    unigrams = Counter()\n",
    "    bigrams = Counter()\n",
    "    for sentence in sentences:\n",
    "        unigrams.update(sentence)\n",
    "        bigrams.update(zip(sentence, sentence[1:]))\n",
    "    return unigrams, bigrams\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0887d7e",
   "metadata": {},
   "source": [
    "# (a) How many non-zero unigrams (in terms of counts) did you get for each corpus?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d8770b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-zero unigrams in news corpus: 13101\n",
      "Number of non-zero unigrams in romance corpus: 7872\n"
     ]
    }
   ],
   "source": [
    "\n",
    "news_data = brown.sents(categories='news')\n",
    "romance_data = brown.sents(categories='romance')\n",
    "\n",
    "# Preprocess data\n",
    "preprocessed_news_data = preprocess_sentences(news_data)\n",
    "preprocessed_romance_data = preprocess_sentences(romance_data)\n",
    "\n",
    "# Compute unigram and bigram models\n",
    "news_unigrams, _ = compute_models(preprocessed_news_data)\n",
    "romance_unigrams, _ = compute_models(preprocessed_romance_data)\n",
    "\n",
    "# Count non-zero unigrams\n",
    "non_zero_unigrams_news = sum(1 for count in news_unigrams.values() if count > 0)\n",
    "non_zero_unigrams_romance = sum(1 for count in romance_unigrams.values() if count > 0)\n",
    "\n",
    "# Print results\n",
    "print(\"Number of non-zero unigrams in news corpus:\", non_zero_unigrams_news)\n",
    "print(\"Number of non-zero unigrams in romance corpus:\", non_zero_unigrams_romance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9be5767",
   "metadata": {},
   "source": [
    "# (b) How many non-zero bigrams (in terms of counts) did you get for each corpus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d85390ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-zero bigrams in news corpus: 59856\n",
      "Number of non-zero bigrams in romance corpus: 36384\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compute unigram and bigram models\n",
    "_, news_bigrams = compute_models(preprocessed_news_data)\n",
    "_, romance_bigrams = compute_models(preprocessed_romance_data)\n",
    "\n",
    "# Count non-zero bigrams\n",
    "non_zero_bigrams_news = sum(1 for count in news_bigrams.values() if count > 0)\n",
    "non_zero_bigrams_romance = sum(1 for count in romance_bigrams.values() if count > 0)\n",
    "\n",
    "# Print results\n",
    "print(\"Number of non-zero bigrams in news corpus:\", non_zero_bigrams_news)\n",
    "print(\"Number of non-zero bigrams in romance corpus:\", non_zero_bigrams_romance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56f3fe4",
   "metadata": {},
   "source": [
    "# (c) List the 10 most common unigrams (in terms of counts) from each dataset with their probabilities P(wt) (using MLE). You can create a table to show the numbers. Any interesting differences between the two?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "87b6b67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 most common unigrams in the news corpus:\n",
      "Word\t\tCount\t\tProbability\n",
      "the\t\t6386\t\t0.065271\n",
      "<s>\t\t4623\t\t0.047252\n",
      "</s>\t\t4623\t\t0.047252\n",
      "of\t\t2861\t\t0.029242\n",
      "and\t\t2186\t\t0.022343\n",
      "to\t\t2144\t\t0.021914\n",
      "a\t\t2130\t\t0.021771\n",
      "in\t\t2020\t\t0.020646\n",
      "for\t\t969\t\t0.009904\n",
      "that\t\t829\t\t0.008473\n",
      "\n",
      "Top 10 most common unigrams in the romance corpus:\n",
      "Word\t\tCount\t\tProbability\n",
      "<s>\t\t4431\t\t0.065659\n",
      "</s>\t\t4431\t\t0.065659\n",
      "the\t\t2988\t\t0.044277\n",
      "and\t\t1905\t\t0.028228\n",
      "to\t\t1517\t\t0.022479\n",
      "a\t\t1383\t\t0.020493\n",
      "of\t\t1202\t\t0.017811\n",
      "he\t\t1068\t\t0.015826\n",
      "was\t\t999\t\t0.014803\n",
      "i\t\t951\t\t0.014092\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculate total number of tokens for each corpus\n",
    "total_news_tokens = sum(news_unigrams.values())\n",
    "total_romance_tokens = sum(romance_unigrams.values())\n",
    "\n",
    "# Sort unigrams by count and select top 10\n",
    "top_news_unigrams = news_unigrams.most_common(10)\n",
    "top_romance_unigrams = romance_unigrams.most_common(10)\n",
    "\n",
    "# Print results\n",
    "print(\"Top 10 most common unigrams in the news corpus:\")\n",
    "print(\"Word\\t\\tCount\\t\\tProbability\")\n",
    "for word, count in top_news_unigrams:\n",
    "    probability = count / total_news_tokens\n",
    "    print(f\"{word}\\t\\t{count}\\t\\t{probability:.6f}\")\n",
    "\n",
    "print(\"\\nTop 10 most common unigrams in the romance corpus:\")\n",
    "print(\"Word\\t\\tCount\\t\\tProbability\")\n",
    "for word, count in top_romance_unigrams:\n",
    "    probability = count / total_romance_tokens\n",
    "    print(f\"{word}\\t\\t{count}\\t\\t{probability:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee96aba5",
   "metadata": {},
   "source": [
    "# (d) List the 10 most common bigrams (in terms of counts) from each dataset with their probabilities P(wt∣wt−1) (using MLE). You can create a table to show the numbers. Any interesting differences between the two?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "49e5f341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 most common bigrams in the news corpus:\n",
      "Bigram\t\tCount\t\tProbability\n",
      "('of', 'the')\t\t849\t\t0.009108\n",
      "('<s>', 'the')\t\t780\t\t0.008368\n",
      "('in', 'the')\t\t589\t\t0.006319\n",
      "('to', 'the')\t\t277\t\t0.002972\n",
      "('on', 'the')\t\t253\t\t0.002714\n",
      "('for', 'the')\t\t220\t\t0.002360\n",
      "('at', 'the')\t\t196\t\t0.002103\n",
      "('<s>', 'he')\t\t192\t\t0.002060\n",
      "('will', 'be')\t\t157\t\t0.001684\n",
      "('that', 'the')\t\t148\t\t0.001588\n",
      "\n",
      "Top 10 most common bigrams in the romance corpus:\n",
      "Bigram\t\tCount\t\tProbability\n",
      "('<s>', 'i')\t\t386\t\t0.006122\n",
      "('<s>', 'he')\t\t372\t\t0.005900\n",
      "('in', 'the')\t\t273\t\t0.004330\n",
      "('<s>', 'she')\t\t244\t\t0.003870\n",
      "('of', 'the')\t\t235\t\t0.003727\n",
      "('<s>', 'the')\t\t230\t\t0.003648\n",
      "('it', 'was')\t\t179\t\t0.002839\n",
      "('<s>', 'it')\t\t154\t\t0.002442\n",
      "('<s>', 'but')\t\t144\t\t0.002284\n",
      "('he', 'was')\t\t142\t\t0.002252\n"
     ]
    }
   ],
   "source": [
    "#d\n",
    "# Calculate total number of bigrams for each corpus\n",
    "total_news_bigrams = sum(news_bigrams.values())\n",
    "total_romance_bigrams = sum(romance_bigrams.values())\n",
    "\n",
    "# Sort bigrams by count and select top 10\n",
    "top_news_bigrams = news_bigrams.most_common(10)\n",
    "top_romance_bigrams = romance_bigrams.most_common(10)\n",
    "\n",
    "# Print results\n",
    "print(\"Top 10 most common bigrams in the news corpus:\")\n",
    "print(\"Bigram\\t\\tCount\\t\\tProbability\")\n",
    "for bigram, count in top_news_bigrams:\n",
    "    probability = count / total_news_bigrams\n",
    "    print(f\"{bigram}\\t\\t{count}\\t\\t{probability:.6f}\")\n",
    "\n",
    "print(\"\\nTop 10 most common bigrams in the romance corpus:\")\n",
    "print(\"Bigram\\t\\tCount\\t\\tProbability\")\n",
    "for bigram, count in top_romance_bigrams:\n",
    "    probability = count / total_romance_bigrams\n",
    "    print(f\"{bigram}\\t\\t{count}\\t\\t{probability:.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8043c278",
   "metadata": {},
   "source": [
    "# Write a function to compute a probability of a given sentence using a n-gram model you built above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0e188b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_sentence_probability(sentence, bigram_model):\n",
    "    probability = 1.0\n",
    "    for i in range(len(sentence) - 1):\n",
    "        # Calculate the probability of each bigram in the sentence\n",
    "        bigram_count = bigram_model[(sentence[i], sentence[i + 1])]\n",
    "        # Check if the bigram exists in the model\n",
    "        if bigram_count == 0:\n",
    "            # If the bigram does not exist, return probability as 0\n",
    "            return 0.0\n",
    "        # Update the overall probability of the sentence\n",
    "        probability *= bigram_count / sum(bigram_model.values())\n",
    "    return probability\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b366304d",
   "metadata": {},
   "source": [
    "# # (e) What is the probability for \"<s> I loved her when she laughed </s>\" when using the bigram model from the news data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "60a72140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of the sentence in the news data using the bigram model: 0.0\n"
     ]
    }
   ],
   "source": [
    "#e\n",
    "# Test the function with the given sentence using the bigram model from the news data\n",
    "sentence = ['<s>', 'i', 'loved', 'her', 'when', 'she', 'laughed', '</s>']\n",
    "news_sentence_probability = compute_sentence_probability(sentence, news_bigrams)\n",
    "\n",
    "print(\"Probability of the sentence in the news data using the bigram model:\", news_sentence_probability)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33e5744",
   "metadata": {},
   "source": [
    "# Write a function to compute a probability of a given sentence using a n-gram model you built above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7669b566",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sentence_probability(sentence, bigram_model):\n",
    "    probability = 1.0\n",
    "    vocabulary_size = len(bigram_model)  # Size of vocabulary\n",
    "    for i in range(len(sentence) - 1):\n",
    "        # Calculate the probability of each bigram in the sentence\n",
    "        bigram_count = bigram_model.get((sentence[i], sentence[i + 1]), 0)\n",
    "        # Calculate the count of the preceding word\n",
    "        preceding_word_count = sum(count for (word1, word2), count in bigram_model.items() if word1 == sentence[i])\n",
    "        # Apply smoothing - add-one smoothing Laplace smoothing\n",
    "        smoothed_count = bigram_count + 1\n",
    "        smoothed_denominator = preceding_word_count + vocabulary_size  # Add vocabulary size for Laplace smoothing\n",
    "        # Update the overall probability of the sentence\n",
    "        probability *= smoothed_count / smoothed_denominator\n",
    "    return probability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d9b4c1",
   "metadata": {},
   "source": [
    "# (f) What is the probability for “<s> I loved her when she laughed </s>” when using the bigram model from the romance data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e0d4c5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of the sentence in the romance data using the bigram model: 1.281235412164812e-26\n"
     ]
    }
   ],
   "source": [
    "#f\n",
    "# Test the function with the given sentence using the bigram model from the romance data\n",
    "romance_sentence_probability = compute_sentence_probability(sentence, romance_bigrams)\n",
    "\n",
    "print(\"Probability of the sentence in the romance data using the bigram model:\", romance_sentence_probability)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af83f1d",
   "metadata": {},
   "source": [
    "# Add an option to your program to do add-one smoothing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f0ea6193",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sentence_probability_with_smoothing(sentence, bigram_model, vocabulary_size):\n",
    "    probability = 1.0\n",
    "    for i in range(len(sentence) - 1):\n",
    "        # Calculate the count of the bigram in the model\n",
    "        bigram_count = bigram_model.get((sentence[i], sentence[i + 1]), 0)\n",
    "        # Calculate the count of the preceding word\n",
    "        preceding_word_count = sum(count for (word1, word2), count in bigram_model.items() if word1 == sentence[i])\n",
    "        # Apply add-one smoothing\n",
    "        smoothed_count = bigram_count + 1\n",
    "        smoothed_denominator = preceding_word_count + vocabulary_size  # Add vocabulary size for smoothing\n",
    "        # Update the overall probability of the sentence\n",
    "        probability *= smoothed_count / smoothed_denominator\n",
    "    return probability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0a3804",
   "metadata": {},
   "source": [
    "# g) After applying add-one smoothing to your bigram models, what are the probabilities for “<s> I loved her when she laughed </s>” when using the model from the news data and the model from the romance data, respectively?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a90c5c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of the sentence in the news data using add-one smoothing: 2.779207842782567e-27\n",
      "Probability of the sentence in the romance data using add-one smoothing: 3.2512661658569625e-22\n"
     ]
    }
   ],
   "source": [
    "# Given sentence\n",
    "sentence = ['<s>', 'i', 'loved', 'her', 'when', 'she', 'laughed', '</s>']\n",
    "\n",
    "# Calculate the probabilities with add-one smoothing for news data\n",
    "news_sentence_probability_with_smoothing = compute_sentence_probability_with_smoothing(\n",
    "    sentence, news_bigrams, vocabulary_size_news)\n",
    "\n",
    "# Calculate the probabilities with add-one smoothing for romance data\n",
    "romance_sentence_probability_with_smoothing = compute_sentence_probability_with_smoothing(\n",
    "    sentence, romance_bigrams, vocabulary_size_romance)\n",
    "\n",
    "print(\"Probability of the sentence in the news data using add-one smoothing:\", news_sentence_probability_with_smoothing)\n",
    "print(\"Probability of the sentence in the romance data using add-one smoothing:\", romance_sentence_probability_with_smoothing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17742cac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b87a586",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6f9ca4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
